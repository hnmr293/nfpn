import unittest
import numpy
import torch
from nfpn.convert import to_hf8, hf8_to_fp16, HF8_MAX

def is_subnormal(v):
    return v < 2 ** -14

def as_fp16(vi: int):
    vf = numpy.array([vi], dtype=numpy.uint16).view(numpy.float16)[0]
    return vf

class TestToHf8(unittest.TestCase):
    
    def test_normal_fp16_normal_hf8(self):
        xs = [
            # exp  value               fp16                   hf8 (expected)
            (-5,   0.03125,            0b0_01010_0000000000,  0b0_111_0000),
            (-6,   0.015625,           0b0_01001_0000000000,  0b0_110_0000),
            (-7,   0.0078125,          0b0_01000_0000000000,  0b0_101_0000),
            (-8,   0.00390625,         0b0_00111_0000000000,  0b0_100_0000),
            (-9,   0.001953125,        0b0_00110_0000000000,  0b0_011_0000),
            (-10,  0.0009765625,       0b0_00101_0000000000,  0b0_010_0000),
            (-11,  0.00048828125,      0b0_00100_0000000000,  0b0_001_0000),
            (-5,  -0.03125,            0b1_01010_0000000000,  0b1_111_0000),
            (-6,  -0.015625,           0b1_01001_0000000000,  0b1_110_0000),
            (-7,  -0.0078125,          0b1_01000_0000000000,  0b1_101_0000),
            (-8,  -0.00390625,         0b1_00111_0000000000,  0b1_100_0000),
            (-9,  -0.001953125,        0b1_00110_0000000000,  0b1_011_0000),
            (-10, -0.0009765625,       0b1_00101_0000000000,  0b1_010_0000),
            (-11, -0.00048828125,      0b1_00100_0000000000,  0b1_001_0000),
        ]
        
        for exp, x, fp16, hf8 in xs:
            xx = torch.tensor([x], dtype=torch.float16)
            
            self.assertEqual(xx[0].item(), x)
            self.assertEqual(xx[0].view(dtype=torch.int16).item() & 0xffff, fp16)
            
            hf = to_hf8(xx)
            
            self.assertEqual(hf.shape, (1,))
            self.assertEqual(hf.view(dtype=torch.uint8).item(), hf8)
            

    def test_normal_fp16_subnormal_hf8(self):
        xs = [
            # exp  value               fp16                   hf8 (expected)
            (-1,   0.5,                0b0_01110_0000000000,  0b0_000_0_111),
            (-2,   0.25,               0b0_01101_0000000000,  0b0_000_0_110),
            (-3,   0.125,              0b0_01100_0000000000,  0b0_000_0_101),
            (-4,   0.0625,             0b0_01011_0000000000,  0b0_000_0_100),
            (-1,  -0.5,                0b1_01110_0000000000,  0b1_000_0_111),
            (-2,  -0.25,               0b1_01101_0000000000,  0b1_000_0_110),
            (-3,  -0.125,              0b1_01100_0000000000,  0b1_000_0_101),
            (-4,  -0.0625,             0b1_01011_0000000000,  0b1_000_0_100),
            (-12,  0.000244140625,     0b0_00011_0000000000,  0b0_000_0_011),
            (-13,  0.0001220703125,    0b0_00010_0000000000,  0b0_000_0_010),
            (-14,  6.103515625e-05,    0b0_00001_0000000000,  0b0_000_0_001),
            (-12, -0.000244140625,     0b1_00011_0000000000,  0b1_000_0_011),
            (-13, -0.0001220703125,    0b1_00010_0000000000,  0b1_000_0_010),
            (-14, -6.103515625e-05,    0b1_00001_0000000000,  0b1_000_0_001),
        ]
        
        for exp, x, fp16, hf8 in xs:
            xx = torch.tensor([x], dtype=torch.float16)
            
            self.assertEqual(xx[0].item(), x)
            self.assertEqual(xx[0].view(dtype=torch.int16).item() & 0xffff, fp16)
            
            hf = to_hf8(xx)
            
            self.assertEqual(hf.shape, (1,))
            self.assertEqual(hf.view(dtype=torch.uint8).item(), hf8, [exp, x, f'{fp16:016b}', f'{hf8:08b}', f'{hf.view(dtype=torch.uint8).item():08b}'])
    
    
    def test_subnormal_fp16_subnormal_hf8(self):
        xs = [
            # exp  value                   fp16                  hf8 (expected)
            (-15, 3.0517578125e-05,        0b0_00000_1000000000, 0b0_000_1000),
            (-16, 1.52587890625e-05,       0b0_00000_0100000000, 0b0_000_0000),
            (-17, 7.62939453125e-06,       0b0_00000_0010000000, 0b0_000_0000),
            (-18, 3.814697265625e-06,      0b0_00000_0001000000, 0b0_000_0000),
            (-19, 1.9073486328125e-06,     0b0_00000_0000100000, 0b0_000_0000),
            (-20, 9.5367431640625e-07,     0b0_00000_0000010000, 0b0_000_0000),
            (-21, 4.76837158203125e-07,    0b0_00000_0000001000, 0b0_000_0000),
            (-22, 2.384185791015625e-07,   0b0_00000_0000000100, 0b0_000_0000),
            (-23, 1.1920928955078125e-07,  0b0_00000_0000000010, 0b0_000_0000),
            (-24, 5.960464477539063e-08,   0b0_00000_0000000001, 0b0_000_0000),
            (-15, -3.0517578125e-05,       0b1_00000_1000000000, 0b1_000_1000),
            (-16, -1.52587890625e-05,      0b1_00000_0100000000, 0b1_000_0000),
            (-17, -7.62939453125e-06,      0b1_00000_0010000000, 0b1_000_0000),
            (-18, -3.814697265625e-06,     0b1_00000_0001000000, 0b1_000_0000),
            (-19, -1.9073486328125e-06,    0b1_00000_0000100000, 0b1_000_0000),
            (-20, -9.5367431640625e-07,    0b1_00000_0000010000, 0b1_000_0000),
            (-21, -4.76837158203125e-07,   0b1_00000_0000001000, 0b1_000_0000),
            (-22, -2.384185791015625e-07,  0b1_00000_0000000100, 0b1_000_0000),
            (-23, -1.1920928955078125e-07, 0b1_00000_0000000010, 0b1_000_0000),
            (-24, -5.960464477539063e-08,  0b1_00000_0000000001, 0b1_000_0000),
        ]
        
        for exp, x, fp16, hf8 in xs:
            xx = torch.tensor([x], dtype=torch.float16)
            
            self.assertEqual(xx[0].item(), x)
            self.assertEqual(xx[0].view(dtype=torch.int16).item() & 0xffff, fp16)
            
            hf = to_hf8(xx)
            
            self.assertEqual(hf.shape, (1,))
            self.assertEqual(hf.view(dtype=torch.uint8).item(), hf8, [exp, x, f'{fp16:016b}', f'{hf8:08b}', f'{hf.view(dtype=torch.uint8).item():08b}'])
    
    
    def test_normal_hf8_combine(self):
        xs = [
            # exp  value               fp16                   hf8 (expected)
            (-5,   0.03125,            0b0_01010_0000000000,  0b0_111_0000),
            (-6,   0.015625,           0b0_01001_0000000000,  0b0_110_0000),
            (-7,   0.0078125,          0b0_01000_0000000000,  0b0_101_0000),
            (-8,   0.00390625,         0b0_00111_0000000000,  0b0_100_0000),
            (-9,   0.001953125,        0b0_00110_0000000000,  0b0_011_0000),
            (-10,  0.0009765625,       0b0_00101_0000000000,  0b0_010_0000),
            (-11,  0.00048828125,      0b0_00100_0000000000,  0b0_001_0000),
            (-5,  -0.03125,            0b1_01010_0000000000,  0b1_111_0000),
            (-6,  -0.015625,           0b1_01001_0000000000,  0b1_110_0000),
            (-7,  -0.0078125,          0b1_01000_0000000000,  0b1_101_0000),
            (-8,  -0.00390625,         0b1_00111_0000000000,  0b1_100_0000),
            (-9,  -0.001953125,        0b1_00110_0000000000,  0b1_011_0000),
            (-10, -0.0009765625,       0b1_00101_0000000000,  0b1_010_0000),
            (-11, -0.00048828125,      0b1_00100_0000000000,  0b1_001_0000),
        ]
        
        fs = [
            # value        fp16            hf8 (expected)
            (1.5,          0b10_0000_0000, 0b1000),
            (1.25,         0b01_0000_0000, 0b0100),
            (1.125,        0b00_1000_0000, 0b0010),
            (1.0625,       0b00_0100_0000, 0b0001),
            (1.03125,      0b00_0010_0000, 0b0000),
            (1.015625,     0b00_0001_0000, 0b0000),
            (1.0078125,    0b00_0000_1000, 0b0000),
            (1.00390625,   0b00_0000_0100, 0b0000),
            (1.001953125,  0b00_0000_0010, 0b0000),
            (1.0009765625, 0b00_0000_0001, 0b0000),
            (1.0,          0b00_0000_0000, 0b0000),
        ]
        
        for exp, x0, fp16_e, hf8_e in xs:
            for x1, fp16_f, hf8_f in fs:
                x = x0 * x1
                
                xx = torch.tensor([x], dtype=torch.float16)
                
                self.assertEqual(xx[0].item(), x)
                self.assertEqual(xx[0].view(dtype=torch.int16).item() & 0xffff, fp16_e | fp16_f, [exp, x0, x1, fp16_e, fp16_f])
        
                hf = to_hf8(xx)
                
                self.assertEqual(hf.shape, (1,))
                self.assertEqual(hf.view(dtype=torch.uint8).item(), hf8_e | hf8_f)
        

    def test_subnormal_hf8_combine(self):
        xs = [
            # exp  value               fp16                   hf8 (expected)
            (-1,   0.5,                0b0_01110_0000000000,  0b0_000_0_111),
            (-2,   0.25,               0b0_01101_0000000000,  0b0_000_0_110),
            (-3,   0.125,              0b0_01100_0000000000,  0b0_000_0_101),
            (-4,   0.0625,             0b0_01011_0000000000,  0b0_000_0_100),
            (-1,  -0.5,                0b1_01110_0000000000,  0b1_000_0_111),
            (-2,  -0.25,               0b1_01101_0000000000,  0b1_000_0_110),
            (-3,  -0.125,              0b1_01100_0000000000,  0b1_000_0_101),
            (-4,  -0.0625,             0b1_01011_0000000000,  0b1_000_0_100),
            (-12,  0.000244140625,     0b0_00011_0000000000,  0b0_000_0_011),
            (-13,  0.0001220703125,    0b0_00010_0000000000,  0b0_000_0_010),
            (-14,  6.103515625e-05,    0b0_00001_0000000000,  0b0_000_0_001),
            (-12, -0.000244140625,     0b1_00011_0000000000,  0b1_000_0_011),
            (-13, -0.0001220703125,    0b1_00010_0000000000,  0b1_000_0_010),
            (-14, -6.103515625e-05,    0b1_00001_0000000000,  0b1_000_0_001),
        ]
        
        fs = [
            # value        fp16            hf8 (expected)
            (1.5,          0b10_0000_0000, 0b1000),
            (1.25,         0b01_0000_0000, 0b0100),
            (1.125,        0b00_1000_0000, 0b0010),
            (1.0625,       0b00_0100_0000, 0b0001),
            (1.03125,      0b00_0010_0000, 0b0000),
            (1.015625,     0b00_0001_0000, 0b0000),
            (1.0078125,    0b00_0000_1000, 0b0000),
            (1.00390625,   0b00_0000_0100, 0b0000),
            (1.001953125,  0b00_0000_0010, 0b0000),
            (1.0009765625, 0b00_0000_0001, 0b0000),
            (1.0,          0b00_0000_0000, 0b0000),
        ]
        
        for exp, x0, fp16_e, hf8_e in xs:
            for x1, fp16_f, hf8_f in fs:
                x = x0 * x1
                
                xx = torch.tensor([x], dtype=torch.float16)
                
                self.assertEqual(xx[0].item(), x)
                self.assertEqual(xx[0].view(dtype=torch.int16).item() & 0xffff, fp16_e | fp16_f)
        
                hf = to_hf8(xx)
                
                self.assertEqual(hf.shape, (1,))
                self.assertEqual(hf.item(), hf8_e | (hf8_f & 0b1000), [exp, x, f'{fp16_e:016b}', f'{hf8_e:08b}', f'{hf.view(dtype=torch.uint8).item():08b}'])

    
class TestToFp16(unittest.TestCase):
    
    def test_normal_hf8(self):
        es = [
            # exp hf8           fp16
            (-11, 0b0_001_0000, 0b0_00100_0000000000),
            (-10, 0b0_010_0000, 0b0_00101_0000000000),
            (-9,  0b0_011_0000, 0b0_00110_0000000000),
            (-8,  0b0_100_0000, 0b0_00111_0000000000),
            (-7,  0b0_101_0000, 0b0_01000_0000000000),
            (-6,  0b0_110_0000, 0b0_01001_0000000000),
            (-5,  0b0_111_0000, 0b0_01010_0000000000),
            (-11, 0b1_001_0000, 0b1_00100_0000000000),
            (-10, 0b1_010_0000, 0b1_00101_0000000000),
            (-9,  0b1_011_0000, 0b1_00110_0000000000),
            (-8,  0b1_100_0000, 0b1_00111_0000000000),
            (-7,  0b1_101_0000, 0b1_01000_0000000000),
            (-6,  0b1_110_0000, 0b1_01001_0000000000),
            (-5,  0b1_111_0000, 0b1_01010_0000000000),
        ]
        
        for exp, hf8_e, fp16_e in es:
            x = torch.tensor([hf8_e], dtype=torch.uint8)
            xs = hf8_to_fp16(x)
            
            self.assertEqual(xs.shape, (1,))
            
            x = xs[0].view(dtype=torch.int16).item() & 0xffff
            
            self.assertEqual(x, fp16_e)
        
        for exp, hf8_e, fp16_e in es:
            for hf8_f in range(1 << 4):
                fp16_f = hf8_f << 6
        
                x = torch.tensor([hf8_e | hf8_f], dtype=torch.uint8)
                xs = hf8_to_fp16(x)
                
                self.assertEqual(xs.shape, (1,))
                
                x = xs[0].view(dtype=torch.int16).item() & 0xffff
                
                self.assertEqual(x, fp16_e | fp16_f)
            
            
    def test_subnormal_hf8_normal_fp16(self):
        pass
    
    def test_subnormal_hf8_subnormal_fp16(self):
        pass


def test_rand(n=1024, seed=1):
    import random
    
    if 0 <= seed:
        random.seed(seed)
    
    i = 0
    while i < n:
        s = random.randint(0, 1)
        e = random.randint(-11, -1) + 15
        f = random.randint(0, 0b0000_0011_1111_1111)
        
        x = (e << 10) | f
        
        if HF8_MAX <= as_fp16(x):
            continue
        
        xx = torch.tensor([x], dtype=torch.int16).view(dtype=torch.float16)
        if s == 1:
            xx = -xx
            x = (s << 15) | x
        
        hf = to_hf8(xx)
        
        yy = hf8_to_fp16(hf)
        
        assert yy.shape == (1,)
        
        y = yy[0].view(dtype=torch.int16).item() & 0xffff
        
        xf, yf = numpy.array([x, y], dtype=numpy.uint16).view(numpy.float16)
        if e in range(-11, -4):
            d = 1 << 6
        else:
            d = 1 << 9
        assert abs(x - y) < d, f'{yf-xf}   x={xf} ({x} {x:016b}), y={yf} ({y} {y:016b}), s={s}, e={e-15} ({e:05b}), f={f:010b}'
        
        i += 1


if __name__ == '__main__':
    unittest.main()
    #test_rand(1024 * 10)
